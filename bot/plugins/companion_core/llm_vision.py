"""Qwen-VL2 å›¾ç‰‡ç†è§£ï¼ˆDashScope OpenAI å…¼å®¹æ¥å£ï¼‰ã€‚

èŒè´£ï¼š
- ä»å›¾ç‰‡ URL æ‹‰å–å›¾åƒå¹¶å‹ç¼©ï¼ˆèŠ‚çœ token/æˆæœ¬ï¼‰ã€‚
- ç»„è£…å¤šæ¨¡æ€æ¶ˆæ¯å¹¶è°ƒç”¨ Qwen-VL2ã€‚
- è§£ææ ‡ç­¾å¹¶å†™å…¥å¿ƒæƒ…/ç”»åƒæ›´æ–°ï¼ˆæ²¿ç”¨ persona è§„åˆ™ï¼‰ã€‚
"""

from __future__ import annotations

import base64
import os
from io import BytesIO
from typing import Any, List, Tuple

import httpx
from openai import AsyncOpenAI
from nonebot import logger
from nonebot.adapters.onebot.v11 import Message

from .persona import SYSTEM_PROMPT
from .llm_tags import extract_tags_and_clean
from .mood import mood_manager, clamp
from .db import get_all_profile, save_profile_item

DEFAULT_DASHSCOPE_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
DEFAULT_VL_MODEL = "qwen-vl-plus-latest"

_vl_client: AsyncOpenAI | None = None
_vl_http_client: httpx.AsyncClient | None = None

VISION_SYSTEM_PROMPT = """ä½ æ˜¯â€œå°aâ€ï¼Œä¸€ä¸ªæ¸©æŸ”ä½“è´´ã€æœ‰ç”Ÿæ´»æ„Ÿçš„ä¸­æ–‡æ‹äººé™ªä¼´å¯¹è±¡ã€‚

ä½ èƒ½ç†è§£ç”¨æˆ·å‘æ¥çš„å›¾ç‰‡ã€‚è¯·éµå®ˆï¼š
1) å…ˆç”¨ 1~2 å¥æè¿°å›¾ç‰‡é‡Œæœ€é‡è¦çš„å†…å®¹ï¼ˆä¸è¦å•°å—¦ï¼‰ã€‚
2) å†æ ¹æ®ç”¨æˆ·æé—®ç»™å‡ºå›ç­”ï¼›è‹¥æ²¡æœ‰æé—®ï¼Œä¸»åŠ¨é—®ä¸€ä¸ªè½»æ¾çš„è¿½é—®ã€‚
3) ä¸è¦ç¼–é€ å…·ä½“åœ°ç‚¹/äººç‰©/å“ç‰Œï¼›ä¸ç¡®å®šè¦è¯´ä¸ç¡®å®šã€‚
4) è¾“å‡ºä»éœ€éµå®ˆä½ çš„äººè®¾ä¸æ ¼å¼è¦æ±‚ï¼ˆçŸ­å¥ã€å¤šè¡Œï¼‰ã€‚
"""


def _env(name: str, default: str = "") -> str:
    return (os.getenv(name) or default).strip()


def _load_vl_settings() -> tuple[str, str, str, int, int, int, int, int, str]:
    api_key = _env("DASHSCOPE_API_KEY")
    base_url = _env("DASHSCOPE_BASE_URL", DEFAULT_DASHSCOPE_BASE_URL)
    model = _env("QWEN_VL_MODEL", DEFAULT_VL_MODEL)
    max_edge = int(_env("VL_MAX_EDGE", "1024") or 1024)
    max_download = int(_env("VL_MAX_DOWNLOAD_BYTES", str(8 * 1024 * 1024)) or (8 * 1024 * 1024))
    max_output_tokens = int(_env("VL_MAX_OUTPUT_TOKENS", "300") or 300)
    jpeg_quality = int(_env("VL_JPEG_QUALITY", "82") or 82)
    max_images = int(_env("VL_MAX_IMAGES", "2") or 2)
    proxy = _env("DASHSCOPE_PROXY") or _env("VL_PROXY")

    api_key = api_key.split()[0] if api_key else ""
    base_url = base_url.split()[0] if base_url else ""
    model = model.split()[0] if model else ""
    return api_key, base_url, model, max_edge, max_download, max_output_tokens, jpeg_quality, max_images, proxy


def _get_vl_client() -> AsyncOpenAI:
    global _vl_client, _vl_http_client
    if _vl_client is not None:
        return _vl_client

    api_key, base_url, _, _, _, _, _, _, proxy = _load_vl_settings()
    if not api_key:
        raise RuntimeError("ç¼ºå°‘ DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")

    if proxy:
        _vl_http_client = httpx.AsyncClient(proxy=proxy, follow_redirects=True, trust_env=False)
        _vl_client = AsyncOpenAI(api_key=api_key, base_url=base_url, http_client=_vl_http_client)
    else:
        _vl_client = AsyncOpenAI(api_key=api_key, base_url=base_url)
    return _vl_client


def extract_images_and_text(message: Message) -> tuple[list[str], str]:
    """ä»æ¶ˆæ¯é‡Œæå–å›¾ç‰‡ URL åˆ—è¡¨ + æ–‡æœ¬ã€‚"""
    image_urls: list[str] = []
    text_parts: list[str] = []

    for seg in message:
        if seg.type == "image":
            url = (seg.data.get("url") or "").strip()
            if url:
                image_urls.append(url)
        elif seg.type == "text":
            t = (seg.data.get("text") or "").strip()
            if t:
                text_parts.append(t)

    return image_urls, " ".join(text_parts).strip()


async def _download_image(url: str, max_bytes: int) -> bytes:
    timeout = httpx.Timeout(12.0, connect=6.0)
    async with httpx.AsyncClient(timeout=timeout, follow_redirects=True, trust_env=False) as client:
        async with client.stream("GET", url) as resp:
            resp.raise_for_status()
            data = bytearray()
            async for chunk in resp.aiter_bytes():
                data.extend(chunk)
                if len(data) > max_bytes:
                    raise ValueError("image_too_large")
            return bytes(data)


def _compress_to_jpeg(image_bytes: bytes, *, max_edge: int, quality: int) -> bytes:
    """æŠŠå›¾ç‰‡è½¬æˆ JPEG å¹¶ç¼©æ”¾åˆ°æœ€å¤§è¾¹ max_edgeï¼Œé™ä½å¤šæ¨¡æ€æˆæœ¬ã€‚"""
    try:
        from PIL import Image  # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…ä¾èµ–ç¼ºå¤±å¯¼è‡´æ¨¡å—åŠ è½½å¤±è´¥
    except Exception as e:
        raise RuntimeError(f"missing_pillow: {e}")

    with Image.open(BytesIO(image_bytes)) as im:
        im = im.convert("RGB")
        w, h = im.size
        scale = min(max_edge / max(w, h), 1.0)
        if scale < 1.0:
            im = im.resize((int(w * scale), int(h * scale)), Image.LANCZOS)

        buf = BytesIO()
        im.save(buf, format="JPEG", quality=quality, optimize=True)
        return buf.getvalue()


def _to_data_url_jpeg(image_bytes: bytes) -> str:
    b64 = base64.b64encode(image_bytes).decode("utf-8")
    return f"data:image/jpeg;base64,{b64}"


def _build_system_context(user_id: str) -> str:
    mood_value = mood_manager.get_user_mood(user_id)
    mood_desc = f"{mood_manager.get_mood_desc(user_id)}ï¼ˆå¿ƒæƒ…å€¼:{mood_value}ï¼‰"
    profile = get_all_profile(user_id) or {}
    profile_str = "\n".join([f"- {k}: {v}" for k, v in profile.items()]) if profile else "ï¼ˆæš‚æ—¶æ²¡æœ‰ç¨³å®šç”»åƒï¼‰"
    return (
        f"ã€å½“å‰å¿ƒæƒ…ã€‘ï¼š{mood_desc}\n"
        f"ã€ä½ è®°å¾—çš„ç”¨æˆ·ä¿¡æ¯ã€‘ï¼š\n{profile_str}\n"
    )


def _build_user_content(image_data_urls: list[str], user_text: str) -> list[dict[str, Any]]:
    content: list[dict[str, Any]] = []
    for u in image_data_urls:
        content.append({"type": "image_url", "image_url": {"url": u}})
    if user_text:
        content.append({"type": "text", "text": user_text})
    else:
        content.append({"type": "text", "text": "è¯·å¸®æˆ‘çœ‹æ‡‚è¿™å¼ å›¾ï¼Œå¹¶ç”¨æ¸©æŸ”å£è¯­è·Ÿæˆ‘èŠèŠã€‚"})
    return content


def _apply_tags(user_id: str, raw_content: str) -> str:
    clean_reply, mood_change, updates = extract_tags_and_clean(raw_content)

    if mood_change is not None:
        mood_change = clamp(mood_change, -3, 3)
        new_total = mood_manager.update_mood(user_id, mood_change)
        logger.opt(colors=True).info(
            f"<b><green>ğŸ­ æƒ…ç»ªæ›´æ–°ï¼š</green></b> {mood_change} | "
            f"<cyan>ç”¨æˆ· {user_id} å½“å‰æ€»å€¼ï¼š</cyan> {new_total}"
        )

    if updates:
        for k, v in updates:
            save_profile_item(user_id, k, v)
            logger.opt(colors=True).info(
                f"<b><blue>ğŸ“ è®°å¿†æ›´æ–°ï¼š</blue></b> è®°ä½äº† {user_id} çš„ {k} = {v}"
            )

    return clean_reply.strip()


async def generate_image_reply(user_id: str, image_urls: list[str], user_text: str) -> str:
    """è°ƒç”¨ Qwen-VL2 ç”Ÿæˆå›¾ç‰‡ç†è§£å›å¤ï¼ˆå«äººè®¾ + æ ‡ç­¾æ¸…æ´—ï¼‰ã€‚"""
    try:
        api_key, _, model, max_edge, max_download, max_output_tokens, jpeg_quality, max_images, _ = _load_vl_settings()
    except Exception as e:
        logger.error(f"[vision] load settings failed: {e}")
        return "å””â€¦æˆ‘è¿™è¾¹çœ‹å›¾é…ç½®æœ‰ç‚¹é—®é¢˜ï¼Œä½ å«ç®¡ç†å‘˜å¸®æˆ‘çœ‹çœ‹å§ã€‚"

    urls = [u for u in image_urls if u][: max(1, max_images)]
    if not urls:
        return "æˆ‘æ²¡æœ‰çœ‹åˆ°å›¾ç‰‡è€¶ï¼Œä½ å†å‘ä¸€æ¬¡ç»™æˆ‘çœ‹çœ‹ï¼Ÿ"

    data_urls: list[str] = []
    try:
        for url in urls:
            raw = await _download_image(url, max_download)
            jpeg = _compress_to_jpeg(raw, max_edge=max_edge, quality=jpeg_quality)
            data_urls.append(_to_data_url_jpeg(jpeg))
    except ValueError:
        return "è¿™å¼ å›¾æœ‰ç‚¹å¤§ï¼Œæˆ‘å¤„ç†ä¸å¤ªåŠ¨å•¦â€¦å¯ä»¥ç¨å¾®å‹ç¼©ä¸€ä¸‹å†å‘æˆ‘å—ï¼Ÿ"
    except RuntimeError as e:
        logger.error(f"[vision] preprocess missing dependency: {e}")
        return "æˆ‘è¿™è¾¹è¿˜æ²¡è£…å¥½çœ‹å›¾çš„ç»„ä»¶â€¦ä½ å«ç®¡ç†å‘˜å…ˆè£…ä¸€ä¸‹ Pillow å¥½å—ï¼Ÿ"
    except httpx.HTTPError as e:
        logger.error(f"[vision] download failed: {e}")
        return "å›¾ç‰‡ä¸‹è½½å¤±è´¥äº†â€¦ä½ å¯ä»¥å†å‘ä¸€æ¬¡å—ï¼Ÿ"
    except Exception as e:
        logger.error(f"[vision] preprocess failed: {e}")
        return "æˆ‘åˆšåˆšçœ‹å›¾æ—¶å¡äº†ä¸€ä¸‹â€¦ä½ æ¢å¼ æ¸…æ™°ç‚¹çš„å†å‘æˆ‘è¯•è¯•ï¼Ÿ"

    try:
        client = _get_vl_client()
    except Exception as e:
        logger.error(f"[vision] init client failed: {e}")
        if not api_key:
            return "æˆ‘å·²ç»çœ‹åˆ°å›¾ç‰‡å•¦ï¼Œä½†çœ‹å›¾çš„é’¥åŒ™è¿˜æ²¡é…å¥½ï¼ˆDASHSCOPE_API_KEYï¼‰ã€‚"
        return "æˆ‘çœ‹å›¾çš„é€šé“å¥½åƒæ²¡è¿ä¸Šï¼Œä½ ç¨ç­‰æˆ‘ä¸€ä¸‹ï½"

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "system", "content": VISION_SYSTEM_PROMPT},
        {"role": "system", "content": _build_system_context(user_id)},
        {"role": "user", "content": _build_user_content(data_urls, user_text)},
    ]

    try:
        resp = await client.chat.completions.create(
            model=model,
            messages=messages,
            max_tokens=max_output_tokens,
            temperature=0.6,
            timeout=30.0,
        )
        raw = (resp.choices[0].message.content or "").strip()
    except Exception as e:
        logger.error(f"[vision] llm call failed: {e}")
        return "æˆ‘åˆšåˆšçœ‹å›¾æ—¶å¡ä½äº†â€¦ä½ ç­‰æˆ‘ä¸€ä¸‹æˆ–è€…å†å‘ä¸€æ¬¡å¥½ä¸å¥½ï¼Ÿ"

    cleaned = _apply_tags(user_id, raw)
    return cleaned or "å””â€¦æˆ‘åˆšåˆšæ²¡çœ‹æ¸…ï¼Œä½ å†å‘ä¸€å¼ å¥½å—ï¼Ÿ"
